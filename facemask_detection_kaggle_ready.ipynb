{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed443e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939d2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc63d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d omkargurav/face-mask-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb14fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "dataset = '/content/face-mask-dataset.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(dataset,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('The dataset is extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_mask_files = os.listdir('/content/data/with_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_mask_files=os.listdir('/content/data/without_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(with_mask_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(without_mask_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b7cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_mask_label=[1]*3725\n",
    "without_mask_label=[0]*3828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb32d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=with_mask_label+without_mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mpimg.imread('/content/data/with_mask/with_mask_1.jpg')\n",
    "imgplot=plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_mask_path='/content/data/with_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3241a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in with_mask_files:\n",
    "  image=Image.open(with_mask_path+img)\n",
    "  image=image.resize((128,128))\n",
    "  image=image.convert('RGB')\n",
    "  image=np.array(image)\n",
    "  data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_mask_path='/content/data/without_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in without_mask_files:\n",
    "  image=Image.open(without_mask_path+img)\n",
    "  image=image.resize((128,128))\n",
    "  image=image.convert('RGB')\n",
    "  image=np.array(image)\n",
    "  data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data)\n",
    "Y=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=X_train/255\n",
    "X_test_scaled=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f264bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes=2\n",
    "model=keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4efcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(128,128,3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499bdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a22726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(128,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(64,activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(num_of_classes,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df2f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bce751",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit(X_train_scaled,Y_train,validation_split=0.1,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39021561",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path=input(\"Enter the path of the image\")\n",
    "input_image=cv2.imread(input_image_path)\n",
    "cv2_imshow(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_resize=cv2.resize(input_image,(128,128))\n",
    "input_image_scaled=input_image_resize/255\n",
    "input_image_reshaped=np.reshape(input_image_scaled,[1,128,128,3])\n",
    "prediction=model.predict(input_image_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db075e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final=np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93064964",
   "metadata": {},
   "outputs": [],
   "source": [
    "if final==1:\n",
    "  print(\"Ther person is wearing a mask\")\n",
    "else:\n",
    "  print(\"The person is not wearing a mask\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
